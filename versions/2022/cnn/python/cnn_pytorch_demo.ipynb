{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for CIFAR10\n",
    "\n",
    "CNN model that can be used for classification tasks. \n",
    "\n",
    "In this demo, we will train a 3-layer CNN on the CIFAR10 dataset. \n",
    "\n",
    "Let us first import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import math\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning import LightningModule, Trainer, Callback\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN using PyTorch `nn.Conv2D`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, n_features=3, kernel_size=3, n_filters=32, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_features, n_filters, kernel_size=kernel_size)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters*2, kernel_size=kernel_size)\n",
    "        self.conv3 = nn.Conv2d(n_filters*2, n_filters*4, kernel_size=kernel_size)\n",
    "        self.fc1 = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = nn.ReLU()(self.conv1(x))\n",
    "        y = nn.MaxPool2d(kernel_size=2)(y)\n",
    "        y = nn.ReLU()(self.conv2(y))\n",
    "        y = nn.MaxPool2d(kernel_size=2)(y)\n",
    "        y = nn.ReLU()(self.conv3(y))\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = self.fc1(y)\n",
    "        return y\n",
    "        # we dont need to compute softmax since it is already\n",
    "        # built into the CE loss function in PyTorch\n",
    "        #return F.log_softmax(y, dim=1)\n",
    "\n",
    "\n",
    "# use this to get the correct input shape for  fc1. In this case,\n",
    "# comment out y=self.fc1(y) and run the code below.\n",
    "#model = SimpleCNN()\n",
    "#data = torch.Tensor(1, 3, 32, 32)\n",
    "#y = model(data)\n",
    "#print(\"Y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Lightning Module for CNN\n",
    "\n",
    "This is the PL module so we can easily change the implementation of the CNN and compare the results.  More detailed results can be found on the `wandb.ai` page.\n",
    "\n",
    "Using `model` parameter, we can easily switch between different model implementations. We also benchmark the result using a ResNet18 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCIFAR10Model(LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=0.001, batch_size=64,\n",
    "                 num_workers=4, max_epochs=30,\n",
    "                 model=SimpleCNN):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model(num_classes=num_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # this is called during fit()\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    # calls to self.log() are recorded in wandb\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"train_loss\", avg_loss, on_epoch=True)\n",
    "\n",
    "    # this is called at the end of an epoch\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = accuracy(y_hat, y) * 100.\n",
    "        # we use y_hat to display predictions during callback\n",
    "        return {\"y_hat\": y_hat, \"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    # this is called at the end of all epochs\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        self.log(\"test_loss\", avg_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", avg_acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    # validation is the same as test\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "       return self.test_step(batch, batch_idx)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.test_epoch_end(outputs)\n",
    "\n",
    "    # we use Adam optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        # this decays the learning rate to 0 after max_epochs using cosine annealing\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    # this is called after model instatiation to initiliaze the datasets and dataloaders\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataloader()\n",
    "        self.test_dataloader()\n",
    "\n",
    "    # build train and test dataloaders using MNIST dataset\n",
    "    # we use simple ToTensor transform\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(\n",
    "                \"./data\", train=True, download=True, \n",
    "                transform=torchvision.transforms.ToTensor()\n",
    "            ),\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(\n",
    "                \"./data\", train=False, download=True, \n",
    "                transform=torchvision.transforms.ToTensor()\n",
    "            ),\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments\n",
    "\n",
    "Please change the `--model` argument to switch between the different models to be used as CIFAR10 classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = ArgumentParser(description=\"PyTorch Lightning MNIST Example\")\n",
    "    parser.add_argument(\"--max-epochs\", type=int, default=30, help=\"num epochs\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=64, help=\"batch size\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"learning rate\")\n",
    "\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=10, help=\"num classes\")\n",
    "\n",
    "    parser.add_argument(\"--devices\", default=1)\n",
    "    parser.add_argument(\"--accelerator\", default='gpu')\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=4, help=\"num workers\")\n",
    "    \n",
    "    #parser.add_argument(\"--model\", default=torchvision.models.resnet18)\n",
    "    parser.add_argument(\"--model\", default=SimpleCNN)\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases Callback\n",
    "\n",
    "The callback logs train and validation metrics to `wandb`. It also logs sample predictions. This is similar to our `WandbCallback` example for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbCallback(Callback):\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        # process first 10 images of the first batch\n",
    "        if batch_idx == 0:\n",
    "            label_human = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "                           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "            n = 10\n",
    "            x, y = batch\n",
    "            outputs = outputs[\"y_hat\"]\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            # log image, ground truth and prediction on wandb table\n",
    "            columns = ['image', 'ground truth', 'prediction']\n",
    "            data = [[wandb.Image(x_i), label_human[y_i], label_human[y_pred]] for x_i, y_i, y_pred in list(\n",
    "                zip(x[:n], y[:n], outputs[:n]))]\n",
    "            wandb_logger.log_table(\n",
    "                key=pl_module.model.__class__.__name__,\n",
    "                columns=columns,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation of Different Models\n",
    "\n",
    "The validation accuracy of our `SimpleCNN` at `~73%`. \n",
    "\n",
    "Meanwhile the ResNet18 model has accuracy of `~78%`. Consider that `SimpleCNN` uses 113k parameters while `ResNet18` uses 11.2M parameters. `SimpleCNN` is very efficient. Recall that our `SimpleMLP` hsa accuracy of `~53%` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LitCIFAR10Model(\n",
      "  (model): SimpleCNN(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n",
      "SimpleCNN\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    model = LitCIFAR10Model(num_classes=args.num_classes,\n",
    "                           lr=args.lr, batch_size=args.batch_size,\n",
    "                           num_workers=args.num_workers,\n",
    "                           model=args.model,)\n",
    "    model.setup()\n",
    "\n",
    "    # printing the model is useful for debugging\n",
    "    print(model)\n",
    "    print(model.model.__class__.__name__)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rowel/github/roatienza/Deep-Learning-Experiments/versions/2022/cnn/python/wandb/run-20220430_201849-3owdqzn0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/rowel/cnn-cifar/runs/3owdqzn0\" target=\"_blank\">exalted-star-5</a></strong> to <a href=\"https://wandb.ai/rowel/cnn-cifar\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | SimpleCNN        | 113 K \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "113 K     Trainable params\n",
      "0         Non-trainable params\n",
      "113 K     Total params\n",
      "0.455     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305f8521877841e2891da0eb5d47ed3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7745a5941ce94c9aa34e55ed62e2de7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed3ad34192e434d9c221316fb32288b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rowel/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:1403: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  \" and \".join(warn_msg) + \" are deprecated. nn.Module.state_dict will not accept them in the future. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5a8e240fb248448211f8f9279a7860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf29fdba9d74432ebeb62eeb2b42467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb758f4d1be48298300edf729049783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fe6145bc104059a85ab7a97b70040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be21b62b92d428382a12250c45b82ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a950079798488e90c8568bbad5be5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f0382987d3400f88cd019de0e2a039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc808c00cdb54d5891f8ef53d092f6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71e86efe8c148849d9145bffc22eaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a831c2b6a729486db38c3b1c05ee9704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d113e6a724a8ca5bc78bad25b7df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546bfc083cc54628bb211403bf4cdb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af431331c8bb494ebbee30a57213d2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816a917e2301467b9f27ddfb84bfdb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291ebfa0f015467487748c1afd845b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf48c8f45b44ad5945818e0e79114b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a32f69cea34da9947e6d5568180fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbceb661d7e44d4aeea461cadd79b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98059d1e3f1a478fadfc00aeb2244b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91eb16578e64f3aa2be032b0fc3e302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b39bb4409b49d28ca649ecf0320dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597d177f0a164852bca2aa80ac144ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090f1ddfc66f48629e55e19950f4e9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524e4c08137a445f946117274c2e4479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a0575e93bd485896710f7ef8e6dd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214c1a9d927f4188aff47a66a6c31e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29f556ab3bb48bfa3432d8356add056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ed970c679b4db2bcb41598b29be7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04f1c7c8e334f2e8c6883273243f347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9e16da89a94b7183671cd30268521d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             73.17874145507812\n",
      "        test_loss           0.8493992686271667\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e38fc4e6a74820b244b84592f7827b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.077 MB of 0.077 MB uploaded (0.023 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 15.0%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>test_loss</td><td>█▆▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_acc</td><td>73.17874</td></tr><tr><td>test_loss</td><td>0.8494</td></tr><tr><td>train_loss</td><td>0.4154</td></tr><tr><td>trainer/global_step</td><td>23460</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-star-5</strong>: <a href=\"https://wandb.ai/rowel/cnn-cifar/runs/3owdqzn0\" target=\"_blank\">https://wandb.ai/rowel/cnn-cifar/runs/3owdqzn0</a><br/>Synced 6 W&B file(s), 31 media file(s), 25 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220430_201849-3owdqzn0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # wandb is a great way to debug and visualize this model\n",
    "    wandb_logger = WandbLogger(project=\"cnn-cifar\")\n",
    "    \n",
    "    trainer = Trainer(accelerator=args.accelerator,\n",
    "                      devices=args.devices,\n",
    "                      max_epochs=args.max_epochs,\n",
    "                      logger=wandb_logger,\n",
    "                      callbacks=[WandbCallback()])\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52772734322c44a04e342c358be70f2ff4d97da358cb3cd38ceb0f6066598be5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
